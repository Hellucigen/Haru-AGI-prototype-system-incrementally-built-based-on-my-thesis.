# attention_framework.py (å®Œæ•´ä¿®æ”¹ç‰ˆï¼Œå‡è®¾åŸä»£ç ç»“æ„)
from nl_driven_activation import extract_triples_from_text
import time
import random
from typing import Dict, Optional
from collections import defaultdict
from Knowledge_Graph import KnowledgeGraph, Node, Edge
from action_executor import ActionExecutor  # å¯¼å…¥executor
from actions.wiki_enricher import enrich_node_from_wikipedia  # å‡è®¾wiki_enricher.pyå·²å¯¼å…¥æˆ–æ•´åˆ
from utils import normalize_concept, generate_node_id  # æ–°å¯¼å…¥å…±äº«å‡½æ•°

class ActivationManager:
    def __init__(self, graph: KnowledgeGraph):
        self.graph = graph
        self.activations: Dict[str, float] = {}
        self.activation_sources: Dict[str, Dict[str, float]] = defaultdict(dict)

        # 0.0 (çº¯ DMN, å‘æ•£) <---> 1.0 (çº¯ CEN, èšç„¦)
        self.lambda_mode = 0.0

        # åŠ¨åŠ›å­¦å‚æ•° (åŸºäºè®ºæ–‡ 2.2.3 DMN vs CEN)
        # DMN: è¡°å‡æ…¢ï¼Œæ‰©æ•£å¹¿ (é€‚åˆè”æƒ³)
        # CEN: è¡°å‡å¿«ï¼Œæ‰©æ•£çª„ (é€‚åˆä»»åŠ¡)
        self.decay_rate_dmn = 0.1  # æé«˜åˆ°0.1ï¼ŒåŠ é€ŸDMNè¡°å‡
        self.decay_rate_cen = 0.2  # ç•¥æé«˜CENè¡°å‡ï¼Œå¿«é€Ÿèšç„¦
        self.spread_factor_dmn = 0.8  # ç•¥é™ä½æ‰©æ•£ï¼Œé˜²æ­¢å¼‚å¸¸ç´¯ç§¯
        self.spread_factor_cen = 0.4

        self.decay_rate = self.decay_rate_dmn
        self.spread_factor = self.spread_factor_dmn
        self._update_params()

    def _update_params(self):
        lm = self.lambda_mode
        self.decay_rate = max(0.08, self.decay_rate_dmn + (self.decay_rate_cen - self.decay_rate_dmn) * lm)  # æœ€å°è¡°å‡0.08ï¼Œé˜²æ­¢å¤ªæ…¢
        self.spread_factor = self.spread_factor_dmn - (self.spread_factor_dmn - self.spread_factor_cen) * lm

    def update_lambda_mode(self, delta: float = 0.0):
        """è°ƒæ•´æ¨¡å¼ï¼Œå¹¶é™åˆ¶åœ¨ 0~1 ä¹‹é—´"""
        self.lambda_mode = max(0.0, min(1.0, self.lambda_mode + delta))
        self._update_params()

    def activate(self, node_id: str, strength: float, source: str = "input"):
        """æ³¨å…¥èƒ½é‡"""
        if node_id in self.graph.nodes:
            self.activations[node_id] = self.activations.get(node_id, 0.0) + strength
            self.activation_sources[node_id][source] = self.activation_sources[node_id].get(source, 0.0) + strength

    def clear_old_activations(self, threshold=0.1):
        """æ¸…é™¤ä½æ¿€æ´»æ®‹ç•™ï¼Œé˜²æ­¢DMNå¹²æ‰°æ–°è¾“å…¥"""
        for nid in list(self.activations.keys()):
            if self.activations[nid] < threshold:
                del self.activations[nid]
                self.activation_sources.pop(nid, None)

    def drift(self):
        """
        [DMN æ ¸å¿ƒ]: å½“ç³»ç»Ÿé—²ç½®æ—¶ï¼ŒåŸºäºæ¦‚ç‡è¿›è¡Œéšæœºè”æƒ³ã€‚
        """
        # å¦‚æœå½“å‰éå¸¸ä¸“æ³¨ (CEN > 0.4)ï¼Œåˆ™ä¸æ¸¸è¡
        if self.lambda_mode > 0.4:
            return None

        # 1. è·å–å½“å‰æœ€æ´»è·ƒçš„æƒ³æ³• (å¦‚æœæœ‰)
        top_node_id = self.get_top_node()

        # 2. ç­–ç•¥A: è”æƒ³æ‰©æ•£ (ä»å½“å‰æƒ³æ³•è·³åˆ°é‚»å±…)
        if top_node_id:
            neighbors = self.graph.out_edges.get(top_node_id, [])
            if neighbors:
                # éšæœºé€‰ä¸€ä¸ªé‚»å±…ï¼Œç»™äºˆå¾®å¼±åˆºæ¿€
                edge = random.choice(neighbors)
                drift_energy = 0.2 * (1.0 - self.lambda_mode)  # è¶Šæ”¾æ¾ï¼Œèƒ½é‡è¶Šå®¹æ˜“æµåŠ¨ï¼Œé™ä½ä»¥é˜²ç´¯ç§¯
                self.activate(edge.dst, drift_energy, source="dmn_assoc")
                return f"ğŸ’­ è”æƒ³: {top_node_id} -> {edge.dst}"

        # 3. ç­–ç•¥B: éšæœºé—ªå¿µ (å¦‚æœæ²¡æœ‰ç„¦ç‚¹ï¼Œæˆ–è€…æ¦‚ç‡è§¦å‘)
        if not top_node_id or random.random() < 0.1:
            all_nodes = list(self.graph.nodes.keys())
            if all_nodes:
                random_node = random.choice(all_nodes)
                self.activate(random_node, 0.4, source="dmn_random")
                return f"âœ¨ é—ªå¿µ: {random_node}"

        return None

    def decay(self):
        """èƒ½é‡è‡ªç„¶è¡°å‡"""
        for nid in list(self.activations.keys()):
            self.activations[nid] -= self.decay_rate
            if self.activations[nid] <= 0:
                del self.activations[nid]
                self.activation_sources.pop(nid, None)

    def spread(self):
        """èƒ½é‡åœ¨å›¾è°±ä¸­ä¼ æ’­"""
        new_contribs = defaultdict(float)

        # ç®€å•çš„å•æ­¥ä¼ æ’­
        for nid, act in self.activations.items():
            neighbors = self.graph.out_edges.get(nid, [])
            if not neighbors:
                continue
            norm_factor = 1.0 / len(neighbors) if len(neighbors) > 0 else 0  # è§„èŒƒåŒ–ï¼Œé˜²æ­¢å¤šè¾¹ç´¯ç§¯
            for edge in neighbors:
                flow = act * edge.weight * self.spread_factor * norm_factor
                if flow > 0.01:
                    new_contribs[edge.dst] += flow

        # åº”ç”¨ä¼ æ’­ç»“æœ
        for dst, flow in new_contribs.items():
            self.activations[dst] = min(2.0, self.activations.get(dst, 0.0) + flow)  # Cap at 2.0ï¼Œé˜²æ­¢å¼‚å¸¸é«˜

    def get_top_node(self) -> Optional[str]:
        if not self.activations:
            return None
        return max(self.activations, key=self.activations.get)

    def get_activation(self, node_id: str) -> float:
        return self.activations.get(node_id, 0.0)


class AttentionFramework:
    def __init__(self, kg_path: str = "knowledge_graph.json"):
        self.graph = KnowledgeGraph.load_from_json(kg_path)
        self.am = ActivationManager(self.graph)

    def inject_text(self, text: str):
        """å¤„ç†å¤–éƒ¨è¾“å…¥"""
        if not text.strip():
            return

        print(f"ğŸ“¥ æ„ŸçŸ¥è¾“å…¥: {text}")

        # æ–°å¢ï¼šæ¸…é™¤æ—§ä½æ¿€æ´»ï¼Œç„¦ç‚¹é‡ç½®
        self.am.clear_old_activations()

        # 1. ç¬é—´æ‹‰é«˜ CEN æ¨¡å¼ (è¿›å…¥ä¸“æ³¨çŠ¶æ€)
        self.am.update_lambda_mode(delta=1.0)

        # 2. æå–è¯­ä¹‰å¹¶æ¿€æ´»
        triples = extract_triples_from_text(text)
        print(f"Extracted triples: {triples}")  # æ—¥å¿—æŸ¥çœ‹LLMè¿”å›

        if not triples:
            # å…œåº•ï¼šæ¿€æ´»è¾“å…¥å…³é”®è¯å¹¶åˆ›å»ºæ–°èŠ‚ç‚¹
            keywords = text.split()[:2]  # ç®€åŒ–ï¼Œå®é™…ç”¨NLP
            for kw in keywords:
                kw_name = normalize_concept(kw)  # è§„èŒƒåŒ–
                kw_id = self.graph.get_node_by_name(kw_name)  # ä½¿ç”¨æ–°æ–¹æ³•
                if not kw_id:
                    kw_id = generate_node_id(kw_name)
                    node = Node(kw_id, "Concept", 0.5, "semantic")
                    current_ts = int(time.time())  # UTCç§’çº§æ—¶é—´æˆ³ï¼Œä»…å±æ€§
                    node.attributes = {"name": kw_name, "created_at": current_ts, "last_accessed": current_ts, "source": "user_input"}
                    self.graph.add_node(node)
                    print(f"Created new node for unknown concept: {kw_name}")
                    # Enrich from Wiki (å‡è®¾summaryéœ€å¤–éƒ¨è·å–ï¼Œè¿™é‡Œæ¨¡æ‹Ÿæˆ–è°ƒç”¨browse_pageè·å–)
                    summary = "Placeholder Wikipedia summary for " + kw_name  # å®é™…ç”¨å·¥å…·è·å–
                    enrich_node_from_wikipedia(self.graph, kw_id, summary)
                self.am.activate(kw_id, 0.8, "unknown_input")
            self.am.spread()  # ç«‹å³ä¼ æ’­
            self.am.spread()  # å¤šä¸€æ¬¡ï¼Œç¡®ä¿ç„¦ç‚¹ç¨³å®š
            return

        # å®Œæ•´å›¾è°±æ›´æ–°ä¸æ¿€æ´»é€»è¾‘
        current_ts = int(time.time())
        existing_names = {normalize_concept(node.attributes.get("name", "")).lower(): nid for nid, node in self.graph.nodes.items()}

        for head, rel, tail in triples:
            head_name = normalize_concept(head)
            tail_name = normalize_concept(tail)
            # Head node
            head_id = existing_names.get(head_name.lower())
            if not head_id:
                head_id = generate_node_id(head_name)
                head_node = Node(head_id, "Concept", 0.5, "semantic")
                head_node.attributes = {"name": head_name, "created_at": current_ts, "last_accessed": current_ts, "source": "llm_triple"}
                self.graph.add_node(head_node)
                existing_names[head_name.lower()] = head_id
                print(f"Created new head node: {head_name}")
                # Enrich if unknown
                summary = "Placeholder Wikipedia summary for " + head_name  # å®é™…è·å–
                enrich_node_from_wikipedia(self.graph, head_id, summary)

            # Tail node
            tail_id = existing_names.get(tail_name.lower())
            if not tail_id:
                tail_id = generate_node_id(tail_name)
                tail_node = Node(tail_id, "Concept", 0.5, "semantic")
                tail_node.attributes = {"name": tail_name, "created_at": current_ts, "last_accessed": current_ts, "source": "llm_triple"}
                self.graph.add_node(tail_node)
                existing_names[tail_name.lower()] = tail_id
                print(f"Created new tail node: {tail_name}")
                # Enrich if unknown
                summary = "Placeholder Wikipedia summary for " + tail_name  # å®é™…è·å–
                enrich_node_from_wikipedia(self.graph, tail_id, summary)

            # Add edge
            edge = Edge(src=head_id, dst=tail_id, relation=rel.upper(), weight=0.7)
            try:
                self.graph.add_edge(edge)
            except ValueError:
                pass  # å·²å­˜åœ¨

            # Activate
            self.am.activate(head_id, 1.0, "input")
            self.am.activate(tail_id, 1.0, "input")

        # ç«‹å³ä¼ æ’­ï¼Œç¡®ä¿ç„¦ç‚¹åˆ‡æ¢
        self.am.spread()
        self.am.spread()  # å¤šä¸€æ¬¡

        # ä¿å­˜æ›´æ–°å›¾è°±
        self.graph.save_to_json("knowledge_graph.json")

    def step(self):
        """å•æ¬¡è®¤çŸ¥å¾ªç¯"""
        # 1. èƒ½é‡æ‰©æ•£
        self.am.spread()
        # 2. èƒ½é‡è¡°å‡
        self.am.decay()
        # 3. æ¨¡å¼å›å½’ (å¦‚æœæ²¡æœ‰å¤–éƒ¨åˆºæ¿€ï¼ŒCEN ä¼šè‡ªç„¶è¡°é€€å› DMN)
        self.am.update_lambda_mode(delta=-0.02)  # æ…¢è¡°é€€ï¼Œä¿æŒç„¦ç‚¹ longer

        # æ–°å¢ï¼šåªåœ¨CENæ¨¡å¼ä¸‹æ‰§è¡ŒåŠ¨ä½œï¼ˆDMNä¸è¡ŒåŠ¨ï¼‰
        if self.am.lambda_mode > 0.4:  # CENé˜ˆå€¼
            executor = ActionExecutor(self.graph, self.am, threshold=0.1)
            executor.execute_pending_actions(current_focus=self.am.get_top_node())